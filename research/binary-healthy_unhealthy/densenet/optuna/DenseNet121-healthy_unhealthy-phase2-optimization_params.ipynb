{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23daeb27-6d24-465d-9cde-995ccc66fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "987c2b09-6faa-4e20-841b-7d123d996c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow / Keras Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow / Keras Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ec3dc7-53b0-4ca4-9749-f4a1121c06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For reproducibility, everything seeded!\n",
      "Enabled memory growth for 1 GPU(s)\n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Using GPU strategy: MirroredStrategy\n",
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "SEED=28\n",
    "seed_everthing()\n",
    "gpu_growth()\n",
    "strategy = get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "034eebd0-643a-43d2-ad79-c17a7af08ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Batch size: 8\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "DATA_DIR = '../../../data/'\n",
    "MODELS_DIR = '../../../models/'\n",
    "IMAGE_SIZE = (256, 256)\n",
    "SHUFFLE_SIZE = 1024\n",
    "MASK_SIZE = IMAGE_SIZE\n",
    "UNFREEZE_LAYER = 'conv5_block1_0_bn'\n",
    "# === CELL 2: ALGORITHM CONFIGS ===\n",
    "PENALIZED_F1_CONFIG = {'alpha_p': 0.5, 'stage': 3}\n",
    "OPTIMIZATION_CONFIG = {'opt_trials': 20, 'opt_warmup_epoch': 3, 'opt_unfreeze_epoch': 5, 'unfreeze_layer': UNFREEZE_LAYER}\n",
    "MODEL_CONFIG = {'img_size': IMAGE_SIZE, 'mask_size': MASK_SIZE}\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 8\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "DATASET_CONFIG = {'shuffle': SHUFFLE_SIZE, 'batch_size': GLOBAL_BATCH_SIZE, 'auto': AUTO}\n",
    "print(f'Global Batch size: {GLOBAL_BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9d0b842-8aa2-46b4-9ce7-0655bdf88617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COVID': 0, 'Normal': 1, 'Viral Pneumonia': 2, 'Lung_Opacity': 3}\n"
     ]
    }
   ],
   "source": [
    "class_mapping_dir = os.path.join(DATA_DIR, 'class_mapping.json')\n",
    "with open(class_mapping_dir, 'r') as f:\n",
    "    class_mapping = json.load(f)\n",
    "\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f24b092-230a-49f9-a9b1-55ff8fbe67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Healthy': 0, 'Unhealthy': 1}\n"
     ]
    }
   ],
   "source": [
    "unhealthy_class_mapping_path = os.path.join(DATA_DIR, 'healthy_binary_mapping.json')\n",
    "with open(unhealthy_class_mapping_path, 'r') as f:\n",
    "    unhealthy_class_mapping = json.load(f)\n",
    "\n",
    "print(unhealthy_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70545fa8-6f15-4247-b8ec-300a3c2dc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: ['../../../data/tfrecords/data_00.tfrecord', '../../../data/tfrecords/data_01.tfrecord', '../../../data/tfrecords/data_02.tfrecord']\n",
      "Val files: ['../../../data/tfrecords/data_09.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "all_files = sorted(tf.io.gfile.glob(os.path.join(DATA_DIR, 'tfrecords/*.tfrecord')))\n",
    "sub_train_files = all_files[:3]\n",
    "val_files = all_files[-1:]\n",
    "print(\n",
    "    f\"Train files: {sub_train_files}\\n\"\n",
    "    f\"Val files: {val_files}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf7bbf47-c966-4507-b360-e9fdf860d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fn = make_parse_fn(image_size=IMAGE_SIZE, mask_size=MASK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34407607-24fb-4135-94db-c92140046f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_augmentation = Sequential([\n",
    "    tfl.Input(shape= IMAGE_SIZE + (3,)),\n",
    "    tfl.RandomFlip('horizontal'),\n",
    "    tfl.RandomRotation(0.05, interpolation='bilinear', fill_mode='nearest', seed=SEED),\n",
    "    tfl.RandomZoom(0.05, interpolation='bilinear', fill_mode='nearest', seed=SEED),\n",
    "    tfl.RandomBrightness(0.05, seed=SEED),\n",
    "    tfl.RandomContrast(0.05, seed=SEED)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e93cc0-be92-4c5f-8f1a-f93fa5f62991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(tfrecords, config=DATASET_CONFIG, is_training= True, image_augmentation=None):\n",
    "    shuffle_size = config[\"shuffle\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    AUTO = config[\"auto\"]\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads= AUTO)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls= AUTO)\n",
    "    dataset = dataset.map(lung_roi_preprocess, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(remap_for_binary, num_parallel_calls=AUTO)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(shuffle_size)\n",
    "        # 1. Batch the data FIRST\n",
    "        dataset = dataset.batch(batch_size, drop_remainder= True)\n",
    "        # 2. Apply augmentation to the entire batch SECOND\n",
    "        if image_augmentation is not None:\n",
    "            dataset = dataset.map(\n",
    "                lambda x, y: (image_augmentation(x, training=True), y), \n",
    "                num_parallel_calls= AUTO\n",
    "            )\n",
    "    else:\n",
    "        # For validation, just batch the data without augmenting\n",
    "        dataset = dataset.batch(batch_size, drop_remainder= True)\n",
    "\n",
    "    dataset = dataset.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls= AUTO)\n",
    "    # 3. Prefetch the augmented batches\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "936f7cdb-6e66-47cb-b0ae-e1a6095875a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Validation datasets are created successfully !\n"
     ]
    }
   ],
   "source": [
    "sub_train_dataset = dataset(sub_train_files, is_training= True, image_augmentation=light_augmentation)\n",
    "val_dataset = dataset(val_files, is_training= False, image_augmentation=light_augmentation)\n",
    "print(f\"Train and Validation datasets are created successfully !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55f43685-4aac-4d90-9834-6049c19bac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna Training Steps: 793\n",
      "Validation Steps: 264\n"
     ]
    }
   ],
   "source": [
    "optuna_steps = count_steps(sub_train_dataset)\n",
    "validation_steps = count_steps(val_dataset)\n",
    "print(f\"Optuna Training Steps: {optuna_steps}\\nValidation Steps: {validation_steps}\")\n",
    "\n",
    "OPTIMIZATION_CONFIG['optuna_steps'] = int(optuna_steps)\n",
    "OPTIMIZATION_CONFIG['validation_steps'] = int(validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e69f78dd-5d08-4b02-9c62-0029192f0c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Architecture metadata: {'best_trial_number': 12, 'best_value': 0.8881901409353111, 'best_hparams': {'num_layers': 2, 'dense_units': [1024, 512]}, 'phase1_settings': {'loss': 'BinaryCrossentropy', 'optimizer': 'Adam', 'lr': 0.0003, 'weight_decay': 0, 'dropout_rate': 0.1}, 'timestamp': 1768602873.5272806, 'seed': 28}\n",
      "Best Architecture Hyperparameters:\n",
      "Number of Dense layers: 2\n",
      "Dense units in order: [1024, 512]\n"
     ]
    }
   ],
   "source": [
    "best_arch_dir = './phase1_architecture/healthy_unhealthy-best_architecture.json'\n",
    "with open(best_arch_dir, 'r') as f:\n",
    "    best_arch = json.load(f)\n",
    "\n",
    "print(f\"Best Architecture metadata: {best_arch}\")\n",
    "print(\n",
    "    f\"Best Architecture Hyperparameters:\\n\"\n",
    "    f\"Number of Dense layers: {best_arch[\"best_hparams\"][\"num_layers\"]}\\n\"\n",
    "    f\"Dense units in order: {best_arch[\"best_hparams\"][\"dense_units\"]}\"\n",
    ")\n",
    "OPTIMIZATION_CONFIG['phase1_hparams'] = best_arch['best_hparams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6842ac4d-91b4-41e5-8a1f-c891df2f39d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_hparams(trial, hparams=best_arch[\"best_hparams\"]):\n",
    "    num_layers = hparams[\"num_layers\"]\n",
    "    hparams[\"lr_stage1\"] = trial.suggest_float(\"lr_stage1\", 1e-4, 1e-3, log=True)\n",
    "    hparams[\"lr_stage2\"] = trial.suggest_float(\"lr_stage2\", 5e-6, 5e-5, log=True)\n",
    "    hparams[\"weight_decay\"] = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    hparams[\"label_smoothing\"] = trial.suggest_categorical(\"label_smoothing\", [0.0, 0.025, 0.05, 0.075, 0.1])\n",
    "    hparams[\"dropout_rate\"] = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.05)\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "915c0fa8-bc14-4bb3-b7dc-e11325402904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet_model(\n",
    "    hparams, dropout_rate,\n",
    "    config=MODEL_CONFIG\n",
    "):\n",
    "    \n",
    "    img_size = config[\"img_size\"]\n",
    "    inputs = tfl.Input(shape= img_size + (3,))\n",
    "    base_model = tf.keras.applications.DenseNet121(\n",
    "        name= 'densenet',\n",
    "        weights= 'imagenet',\n",
    "        include_top= False\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    for layer in base_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    \n",
    "    densenet = base_model(inputs, training= False)\n",
    "    x = tfl.GlobalAveragePooling2D()(densenet)\n",
    "    num_dense_layers = hparams[\"num_layers\"]\n",
    "    for i in range(num_dense_layers):\n",
    "        units = hparams[\"dense_units\"][i]\n",
    "        x = tfl.Dense(units, activation= 'relu', name=f\"head_dense_{i+1}\")(x)\n",
    "        dropout = tfl.Dropout(dropout_rate, name=f\"dropout_{i+1}\")\n",
    "        x = dropout(x, training=True)\n",
    "\n",
    "    outputs = tfl.Dense(1, activation= 'sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa9ebb2d-5547-475d-b752-e4c1e10ba126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_backbone(model, backbone_name= None, unfreeze_layer= None):\n",
    "    base_model = model.get_layer(backbone_name)\n",
    "    \n",
    "    if unfreeze_layer is None:\n",
    "        # Stage 1: Freeze everything\n",
    "        base_model.trainable = False\n",
    "        return model\n",
    "\n",
    "    # Stage 2: Selective Unfreezing\n",
    "    base_model.trainable = True\n",
    "    unfreeze_flag = False\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        if layer.name == unfreeze_layer:\n",
    "            unfreeze_flag = True\n",
    "        \n",
    "        if unfreeze_flag:\n",
    "            # PROFESSIONAL RULE: Always keep BatchNormalization frozen during fine-tuning\n",
    "            # to avoid destroying the moving mean/variance statistics.\n",
    "            if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b99f535-4cb4-4c1e-a65a-0ae15be426ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, loss, optimizer):\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\n",
    "            metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "            metrics.Precision(name=\"precision\"),\n",
    "            metrics.Recall(name=\"recall\"),\n",
    "            metrics.AUC(name='AUC')\n",
    "        ],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69d4ec6c-0c1b-4e20-b4e9-ac4bb444dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_f1_score(history, config):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Your exact rolling window penalized F1 score function\n",
    "    \"\"\"\n",
    "    alpha_p = config['alpha_p']\n",
    "    stage_epochs = config['stage']\n",
    "\n",
    "    val_prec = np.array(history.history[\"val_precision\"])\n",
    "    val_rec = np.array(history.history[\"val_recall\"])\n",
    "    val_f1 = np.array(2*(np.multiply(val_prec, val_rec)) / np.add(val_prec, val_rec))\n",
    "    \n",
    "    # Use last N epochs (adaptive for short architecture search)\n",
    "    stage_epochs = min(stage_epochs, len(val_f1))\n",
    "    f1 = np.mean(val_f1[-stage_epochs:])\n",
    "    prec = np.mean(val_prec[-stage_epochs:])\n",
    "    rec = np.mean(val_rec[-stage_epochs:])\n",
    "\n",
    "    train_loss = history.history[\"loss\"][-1]\n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    loss_penalty = alpha_p * (val_loss - train_loss)\n",
    "        \n",
    "    # Your gap penalty\n",
    "    gap_penalty = alpha_p * abs(prec - rec)\n",
    "    score = f1 - gap_penalty - loss_penalty\n",
    "    \n",
    "    return score, f1, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1e094a5-bea3-4ced-ae69-508b51ac584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_optimization(trial, config=OPTIMIZATION_CONFIG):\n",
    "    print('='*180)\n",
    "    print(f\"Trial {trial.number+1}/{config[\"opt_trials\"]} started...\")\n",
    "    model = None\n",
    "    history = None\n",
    "    callbacks = None\n",
    "    warmup_epoch = config['opt_warmup_epoch']\n",
    "    unfreeze_epoch = config[\"opt_unfreeze_epoch\"]\n",
    "    total_epoch = warmup_epoch + unfreeze_epoch\n",
    "    optuna_steps = config['optuna_steps']\n",
    "    validation_steps = config['validation_steps']\n",
    "    arch_hparams = config['phase1_hparams']\n",
    "    unfreeze_layer = config[\"unfreeze_layer\"]\n",
    "    hparams = optimization_hparams(trial, hparams=arch_hparams)\n",
    "    trial.set_user_attr(\"hparams\", hparams)\n",
    "    dropout_rate = hparams[\"dropout_rate\"]\n",
    "    loss = BinaryCrossentropy(\n",
    "        label_smoothing=hparams['label_smoothing']\n",
    "    )\n",
    "    try:\n",
    "        with strategy.scope():\n",
    "                \n",
    "            optimizer = AdamW(\n",
    "                learning_rate=hparams[\"lr_stage1\"],\n",
    "                weight_decay=hparams[\"weight_decay\"]\n",
    "            )\n",
    "            model = densenet_model(\n",
    "                hparams, \n",
    "                dropout_rate=dropout_rate,\n",
    "                config=MODEL_CONFIG\n",
    "            )\n",
    "            model = compile_model(model, loss=loss, optimizer=optimizer)\n",
    "        history = model.fit(\n",
    "                sub_train_dataset.repeat(),\n",
    "                validation_data=val_dataset.repeat(),\n",
    "                epochs=warmup_epoch,\n",
    "                steps_per_epoch=optuna_steps,\n",
    "                validation_steps=validation_steps,\n",
    "            )\n",
    "        with strategy.scope():\n",
    "            model = unfreeze_backbone(\n",
    "                model,\n",
    "                backbone_name='densenet',\n",
    "                unfreeze_layer=unfreeze_layer\n",
    "            )\n",
    "            decay_steps = total_epoch * optuna_steps\n",
    "            lr = CosineDecay(\n",
    "                decay_steps=decay_steps,\n",
    "                initial_learning_rate=hparams[\"lr_stage2\"],\n",
    "                alpha=0.0\n",
    "            )\n",
    "            optimizer = AdamW(\n",
    "                learning_rate=lr,\n",
    "                weight_decay=hparams[\"weight_decay\"]\n",
    "            )\n",
    "            model = compile_model(model, loss=loss, optimizer=optimizer)\n",
    "            \n",
    "        earlystop_cb = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "        )\n",
    "        callbacks = [earlystop_cb]\n",
    "        history = model.fit(\n",
    "            sub_train_dataset.repeat(),\n",
    "            validation_data=val_dataset.repeat(),\n",
    "            initial_epoch=warmup_epoch,\n",
    "            epochs=total_epoch,\n",
    "            steps_per_epoch=optuna_steps,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        score, best_f1, best_prec, best_rec = penalized_f1_score(history, config=PENALIZED_F1_CONFIG)\n",
    "        last_train_loss = history.history[\"loss\"][-1]\n",
    "        last_val_loss = history.history[\"val_loss\"][-1]\n",
    "        trial.set_user_attr(\"phase2_score\", float(score))\n",
    "        print(f\"Penalized F1: {score:.4f}, Best F1: {best_f1:.4f}, P: {best_prec:.4f}, R: {best_rec:.4f}\")\n",
    "        print(f\"Last Epoch --> Train Loss: {last_train_loss} | Val Loss: {last_val_loss}\")\n",
    "        return score\n",
    "    finally:\n",
    "        cleanup(model, history, callbacks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6326f70-e5ca-4101-84a7-53840ab9d991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 14:30:02,705] A new study created in RDB with name: no-name-86f7d791-46ff-4a82-bec7-5f0dada29a1a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================================================================================\n",
      "Trial 1/20 started...\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 14:30:13.702402: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
      "2026-01-21 14:30:14.783474: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 135ms/step - AUC: 0.8837 - accuracy: 0.8026 - loss: 0.4922 - precision: 0.8193 - recall: 0.7949 - val_AUC: 0.9292 - val_accuracy: 0.8333 - val_loss: 0.4608 - val_precision: 0.9464 - val_recall: 0.7050\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9242 - accuracy: 0.8482 - loss: 0.4338 - precision: 0.8682 - recall: 0.8342 - val_AUC: 0.9365 - val_accuracy: 0.8542 - val_loss: 0.4301 - val_precision: 0.9396 - val_recall: 0.7555\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - AUC: 0.9356 - accuracy: 0.8636 - loss: 0.4156 - precision: 0.8859 - recall: 0.8491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 14:35:10.780916: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: Function was cancelled before it was started\n",
      "\t [[{{node RemoteCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9329 - accuracy: 0.8618 - loss: 0.4187 - precision: 0.8791 - recall: 0.8505 - val_AUC: 0.9443 - val_accuracy: 0.8665 - val_loss: 0.4108 - val_precision: 0.8376 - val_recall: 0.9077\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 150ms/step - AUC: 0.9501 - accuracy: 0.8824 - loss: 0.3872 - precision: 0.8987 - recall: 0.8714 - val_AUC: 0.9494 - val_accuracy: 0.8925 - val_loss: 0.3851 - val_precision: 0.9087 - val_recall: 0.8716\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 147ms/step - AUC: 0.9556 - accuracy: 0.8955 - loss: 0.3752 - precision: 0.9125 - recall: 0.8834 - val_AUC: 0.9529 - val_accuracy: 0.8958 - val_loss: 0.3801 - val_precision: 0.9342 - val_recall: 0.8506\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9617 - accuracy: 0.9027 - loss: 0.3638 - precision: 0.9173 - recall: 0.8930 - val_AUC: 0.9570 - val_accuracy: 0.9048 - val_loss: 0.3684 - val_precision: 0.9259 - val_recall: 0.8792\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9640 - accuracy: 0.9059 - loss: 0.3589 - precision: 0.9236 - recall: 0.8925 - val_AUC: 0.9576 - val_accuracy: 0.9034 - val_loss: 0.3664 - val_precision: 0.9197 - val_recall: 0.8830\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9645 - accuracy: 0.9056 - loss: 0.3573 - precision: 0.9225 - recall: 0.8931 - val_AUC: 0.9588 - val_accuracy: 0.9015 - val_loss: 0.3658 - val_precision: 0.9057 - val_recall: 0.8953\n",
      "Penalized F1: 0.8812, Best F1: 0.9011, P: 0.9171, R: 0.8858\n",
      "Last Epoch --> Train Loss: 0.35733562707901 | Val Loss: 0.3658250570297241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 14:45:33,109] Trial 0 finished with value: 0.8812422507958934 and parameters: {'lr_stage1': 0.00024103656818842467, 'lr_stage2': 6.60354814168357e-06, 'weight_decay': 4.6001544618694844e-05, 'label_smoothing': 0.1, 'dropout_rate': 0.2}. Best is trial 0 with value: 0.8812422507958934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 3558.90 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 2/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - AUC: 0.8318 - accuracy: 0.7632 - loss: 0.5281 - precision: 0.7746 - recall: 0.7725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 14:47:04.864099: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 136ms/step - AUC: 0.8767 - accuracy: 0.7978 - loss: 0.4607 - precision: 0.8111 - recall: 0.7951 - val_AUC: 0.9288 - val_accuracy: 0.8277 - val_loss: 0.4091 - val_precision: 0.9550 - val_recall: 0.6860\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9187 - accuracy: 0.8496 - loss: 0.3826 - precision: 0.8735 - recall: 0.8305 - val_AUC: 0.9366 - val_accuracy: 0.8518 - val_loss: 0.3713 - val_precision: 0.9478 - val_recall: 0.7431\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 132ms/step - AUC: 0.9297 - accuracy: 0.8589 - loss: 0.3577 - precision: 0.8828 - recall: 0.8396 - val_AUC: 0.9422 - val_accuracy: 0.8665 - val_loss: 0.3452 - val_precision: 0.9384 - val_recall: 0.7831\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 152ms/step - AUC: 0.9459 - accuracy: 0.8860 - loss: 0.3222 - precision: 0.9060 - recall: 0.8705 - val_AUC: 0.9517 - val_accuracy: 0.8925 - val_loss: 0.3097 - val_precision: 0.9008 - val_recall: 0.8811\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9571 - accuracy: 0.8971 - loss: 0.2941 - precision: 0.9192 - recall: 0.8787 - val_AUC: 0.9581 - val_accuracy: 0.8892 - val_loss: 0.3094 - val_precision: 0.9514 - val_recall: 0.8192\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9630 - accuracy: 0.9048 - loss: 0.2779 - precision: 0.9245 - recall: 0.8891 - val_AUC: 0.9593 - val_accuracy: 0.8916 - val_loss: 0.2955 - val_precision: 0.9438 - val_recall: 0.8316\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9658 - accuracy: 0.9083 - loss: 0.2688 - precision: 0.9286 - recall: 0.8919 - val_AUC: 0.9613 - val_accuracy: 0.9039 - val_loss: 0.2790 - val_precision: 0.9141 - val_recall: 0.8906\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9702 - accuracy: 0.9174 - loss: 0.2562 - precision: 0.9330 - recall: 0.9057 - val_AUC: 0.9632 - val_accuracy: 0.9058 - val_loss: 0.2734 - val_precision: 0.9176 - val_recall: 0.8906\n",
      "Penalized F1: 0.8610, Best F1: 0.8967, P: 0.9252, R: 0.8709\n",
      "Last Epoch --> Train Loss: 0.25623154640197754 | Val Loss: 0.27338236570358276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 15:01:00,907] Trial 1 finished with value: 0.8610398135707877 and parameters: {'lr_stage1': 0.00037354743204901094, 'lr_stage2': 1.2960517930379114e-05, 'weight_decay': 0.0006395360861223039, 'label_smoothing': 0.025, 'dropout_rate': 0.30000000000000004}. Best is trial 0 with value: 0.8812422507958934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 3725.77 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 3/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 136ms/step - AUC: 0.8759 - accuracy: 0.8019 - loss: 0.4433 - precision: 0.8189 - recall: 0.7938 - val_AUC: 0.9276 - val_accuracy: 0.8641 - val_loss: 0.3403 - val_precision: 0.8938 - val_recall: 0.8249\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9147 - accuracy: 0.8443 - loss: 0.3672 - precision: 0.8653 - recall: 0.8290 - val_AUC: 0.9369 - val_accuracy: 0.8433 - val_loss: 0.3499 - val_precision: 0.9444 - val_recall: 0.7279\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 133ms/step - AUC: 0.9229 - accuracy: 0.8540 - loss: 0.3501 - precision: 0.8780 - recall: 0.8349 - val_AUC: 0.9380 - val_accuracy: 0.8466 - val_loss: 0.3642 - val_precision: 0.9584 - val_recall: 0.7231\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - AUC: 0.9413 - accuracy: 0.8754 - loss: 0.3020 - precision: 0.8988 - recall: 0.8553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 15:08:14.624699: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 152ms/step - AUC: 0.9436 - accuracy: 0.8755 - loss: 0.2966 - precision: 0.8984 - recall: 0.8569 - val_AUC: 0.9530 - val_accuracy: 0.8812 - val_loss: 0.2932 - val_precision: 0.9515 - val_recall: 0.8021\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9555 - accuracy: 0.8881 - loss: 0.2646 - precision: 0.9093 - recall: 0.8712 - val_AUC: 0.9587 - val_accuracy: 0.9015 - val_loss: 0.2560 - val_precision: 0.9386 - val_recall: 0.8582\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9565 - accuracy: 0.8988 - loss: 0.2587 - precision: 0.9238 - recall: 0.8772 - val_AUC: 0.9589 - val_accuracy: 0.9034 - val_loss: 0.2584 - val_precision: 0.9353 - val_recall: 0.8658\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9623 - accuracy: 0.9068 - loss: 0.2414 - precision: 0.9294 - recall: 0.8878 - val_AUC: 0.9608 - val_accuracy: 0.8930 - val_loss: 0.2632 - val_precision: 0.9528 - val_recall: 0.8259\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9671 - accuracy: 0.9094 - loss: 0.2261 - precision: 0.9309 - recall: 0.8917 - val_AUC: 0.9619 - val_accuracy: 0.9053 - val_loss: 0.2497 - val_precision: 0.9503 - val_recall: 0.8544\n",
      "Penalized F1: 0.8341, Best F1: 0.8946, P: 0.9461, R: 0.8487\n",
      "Last Epoch --> Train Loss: 0.22610194981098175 | Val Loss: 0.2496654987335205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 15:16:31,020] Trial 2 finished with value: 0.8341302299230489 and parameters: {'lr_stage1': 0.0001439750889296569, 'lr_stage2': 1.2970924640766352e-05, 'weight_decay': 4.9625473303224696e-06, 'label_smoothing': 0.0, 'dropout_rate': 0.4}. Best is trial 0 with value: 0.8812422507958934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 3765.66 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 4/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 136ms/step - AUC: 0.8546 - accuracy: 0.7765 - loss: 0.5106 - precision: 0.7937 - recall: 0.7691 - val_AUC: 0.9191 - val_accuracy: 0.8561 - val_loss: 0.4059 - val_precision: 0.8903 - val_recall: 0.8107\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9024 - accuracy: 0.8252 - loss: 0.4338 - precision: 0.8474 - recall: 0.8085 - val_AUC: 0.9326 - val_accuracy: 0.8598 - val_loss: 0.3989 - val_precision: 0.8460 - val_recall: 0.8782\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9185 - accuracy: 0.8485 - loss: 0.4055 - precision: 0.8681 - recall: 0.8351 - val_AUC: 0.9372 - val_accuracy: 0.8731 - val_loss: 0.3731 - val_precision: 0.9065 - val_recall: 0.8306\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - AUC: 0.9322 - accuracy: 0.8639 - loss: 0.3785 - precision: 0.8878 - recall: 0.8488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 15:23:45.103224: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 150ms/step - AUC: 0.9356 - accuracy: 0.8643 - loss: 0.3725 - precision: 0.8871 - recall: 0.8464 - val_AUC: 0.9477 - val_accuracy: 0.8830 - val_loss: 0.3476 - val_precision: 0.9052 - val_recall: 0.8544\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 147ms/step - AUC: 0.9453 - accuracy: 0.8799 - loss: 0.3526 - precision: 0.9044 - recall: 0.8593 - val_AUC: 0.9529 - val_accuracy: 0.8949 - val_loss: 0.3376 - val_precision: 0.9076 - val_recall: 0.8782\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9533 - accuracy: 0.8911 - loss: 0.3355 - precision: 0.9091 - recall: 0.8779 - val_AUC: 0.9549 - val_accuracy: 0.8920 - val_loss: 0.3298 - val_precision: 0.9195 - val_recall: 0.8582\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9583 - accuracy: 0.8979 - loss: 0.3232 - precision: 0.9196 - recall: 0.8799 - val_AUC: 0.9559 - val_accuracy: 0.8973 - val_loss: 0.3273 - val_precision: 0.9129 - val_recall: 0.8773\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9594 - accuracy: 0.8977 - loss: 0.3206 - precision: 0.9181 - recall: 0.8816 - val_AUC: 0.9570 - val_accuracy: 0.8968 - val_loss: 0.3242 - val_precision: 0.9254 - val_recall: 0.8620\n",
      "Penalized F1: 0.8632, Best F1: 0.8917, P: 0.9193, R: 0.8658\n",
      "Last Epoch --> Train Loss: 0.3205823004245758 | Val Loss: 0.3242410123348236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 15:31:59,483] Trial 3 finished with value: 0.8631682442567341 and parameters: {'lr_stage1': 0.00019767556594192597, 'lr_stage2': 6.779463183568744e-06, 'weight_decay': 0.00016267017509656023, 'label_smoothing': 0.05, 'dropout_rate': 0.5}. Best is trial 0 with value: 0.8812422507958934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 3874.18 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 5/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 136ms/step - AUC: 0.8886 - accuracy: 0.8113 - loss: 0.4194 - precision: 0.8364 - recall: 0.7914 - val_AUC: 0.9328 - val_accuracy: 0.8584 - val_loss: 0.3274 - val_precision: 0.9159 - val_recall: 0.7878\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9239 - accuracy: 0.8528 - loss: 0.3485 - precision: 0.8808 - recall: 0.8284 - val_AUC: 0.9395 - val_accuracy: 0.8769 - val_loss: 0.3339 - val_precision: 0.8928 - val_recall: 0.8554\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9316 - accuracy: 0.8651 - loss: 0.3280 - precision: 0.8907 - recall: 0.8436 - val_AUC: 0.9442 - val_accuracy: 0.8821 - val_loss: 0.3036 - val_precision: 0.9018 - val_recall: 0.8563\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 152ms/step - AUC: 0.9484 - accuracy: 0.8824 - loss: 0.2851 - precision: 0.9117 - recall: 0.8563 - val_AUC: 0.9512 - val_accuracy: 0.8840 - val_loss: 0.2787 - val_precision: 0.9269 - val_recall: 0.8325\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9542 - accuracy: 0.8920 - loss: 0.2670 - precision: 0.9209 - recall: 0.8663 - val_AUC: 0.9525 - val_accuracy: 0.8849 - val_loss: 0.2793 - val_precision: 0.9382 - val_recall: 0.8230\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9598 - accuracy: 0.8993 - loss: 0.2513 - precision: 0.9264 - recall: 0.8755 - val_AUC: 0.9554 - val_accuracy: 0.8977 - val_loss: 0.2650 - val_precision: 0.9300 - val_recall: 0.8592\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 179ms/step - AUC: 0.9612 - accuracy: 0.9020 - loss: 0.2446 - precision: 0.9292 - recall: 0.8778 - val_AUC: 0.9571 - val_accuracy: 0.8963 - val_loss: 0.2609 - val_precision: 0.9351 - val_recall: 0.8506\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9631 - accuracy: 0.9035 - loss: 0.2413 - precision: 0.9309 - recall: 0.8794 - val_AUC: 0.9585 - val_accuracy: 0.9010 - val_loss: 0.2546 - val_precision: 0.9367 - val_recall: 0.8592\n",
      "Penalized F1: 0.8480, Best F1: 0.8934, P: 0.9339, R: 0.8563\n",
      "Last Epoch --> Train Loss: 0.24132685363292694 | Val Loss: 0.2546301782131195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 15:47:58,307] Trial 4 finished with value: 0.8479840230718849 and parameters: {'lr_stage1': 0.0009324942777854162, 'lr_stage2': 5.7844317403954996e-06, 'weight_decay': 2.918930122219073e-06, 'label_smoothing': 0.0, 'dropout_rate': 0.15000000000000002}. Best is trial 0 with value: 0.8812422507958934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 3966.43 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 6/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 137ms/step - AUC: 0.8928 - accuracy: 0.8189 - loss: 0.4807 - precision: 0.8407 - recall: 0.8032 - val_AUC: 0.9317 - val_accuracy: 0.8660 - val_loss: 0.4286 - val_precision: 0.8848 - val_recall: 0.8402\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9235 - accuracy: 0.8498 - loss: 0.4330 - precision: 0.8714 - recall: 0.8335 - val_AUC: 0.9420 - val_accuracy: 0.8584 - val_loss: 0.4252 - val_precision: 0.9466 - val_recall: 0.7583\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 133ms/step - AUC: 0.9371 - accuracy: 0.8659 - loss: 0.4103 - precision: 0.8854 - recall: 0.8518 - val_AUC: 0.9459 - val_accuracy: 0.8414 - val_loss: 0.4557 - val_precision: 0.9723 - val_recall: 0.7012\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 152ms/step - AUC: 0.9475 - accuracy: 0.8802 - loss: 0.3907 - precision: 0.9005 - recall: 0.8649 - val_AUC: 0.9580 - val_accuracy: 0.8930 - val_loss: 0.3723 - val_precision: 0.9393 - val_recall: 0.8392\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9588 - accuracy: 0.8994 - loss: 0.3676 - precision: 0.9193 - recall: 0.8836 - val_AUC: 0.9588 - val_accuracy: 0.9025 - val_loss: 0.3656 - val_precision: 0.9066 - val_recall: 0.8963\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 148ms/step - AUC: 0.9664 - accuracy: 0.9078 - loss: 0.3506 - precision: 0.9241 - recall: 0.8958 - val_AUC: 0.9634 - val_accuracy: 0.9067 - val_loss: 0.3539 - val_precision: 0.9304 - val_recall: 0.8782\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9710 - accuracy: 0.9187 - loss: 0.3381 - precision: 0.9362 - recall: 0.9049 - val_AUC: 0.9651 - val_accuracy: 0.9062 - val_loss: 0.3524 - val_precision: 0.9043 - val_recall: 0.9077\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9745 - accuracy: 0.9240 - loss: 0.3287 - precision: 0.9418 - recall: 0.9098 - val_AUC: 0.9673 - val_accuracy: 0.9105 - val_loss: 0.3430 - val_precision: 0.9234 - val_recall: 0.8944\n",
      "Penalized F1: 0.8860, Best F1: 0.9061, P: 0.9194, R: 0.8934\n",
      "Last Epoch --> Train Loss: 0.32867759466171265 | Val Loss: 0.34298205375671387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 16:03:34,578] Trial 5 finished with value: 0.8859530084192327 and parameters: {'lr_stage1': 0.0007229369908649282, 'lr_stage2': 2.3009917819996243e-05, 'weight_decay': 0.00019354797400820026, 'label_smoothing': 0.1, 'dropout_rate': 0.1}. Best is trial 5 with value: 0.8859530084192327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4117.17 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 7/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - AUC: 0.8651 - accuracy: 0.7848 - loss: 0.5109 - precision: 0.8076 - recall: 0.7880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 16:05:07.836666: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 137ms/step - AUC: 0.8956 - accuracy: 0.8173 - loss: 0.4767 - precision: 0.8356 - recall: 0.8064 - val_AUC: 0.9313 - val_accuracy: 0.8385 - val_loss: 0.4539 - val_precision: 0.9471 - val_recall: 0.7155\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9331 - accuracy: 0.8600 - loss: 0.4197 - precision: 0.8792 - recall: 0.8466 - val_AUC: 0.9433 - val_accuracy: 0.8670 - val_loss: 0.4231 - val_precision: 0.9385 - val_recall: 0.7840\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 133ms/step - AUC: 0.9365 - accuracy: 0.8644 - loss: 0.4136 - precision: 0.8805 - recall: 0.8548 - val_AUC: 0.9467 - val_accuracy: 0.8845 - val_loss: 0.3946 - val_precision: 0.9199 - val_recall: 0.8411\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 154ms/step - AUC: 0.9468 - accuracy: 0.8819 - loss: 0.3928 - precision: 0.9002 - recall: 0.8688 - val_AUC: 0.9568 - val_accuracy: 0.8688 - val_loss: 0.4154 - val_precision: 0.9697 - val_recall: 0.7602\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9601 - accuracy: 0.8993 - loss: 0.3652 - precision: 0.9194 - recall: 0.8833 - val_AUC: 0.9613 - val_accuracy: 0.9006 - val_loss: 0.3607 - val_precision: 0.9340 - val_recall: 0.8611\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 148ms/step - AUC: 0.9659 - accuracy: 0.9108 - loss: 0.3503 - precision: 0.9262 - recall: 0.8997 - val_AUC: 0.9647 - val_accuracy: 0.9105 - val_loss: 0.3510 - val_precision: 0.9250 - val_recall: 0.8925\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9720 - accuracy: 0.9239 - loss: 0.3317 - precision: 0.9398 - recall: 0.9115 - val_AUC: 0.9683 - val_accuracy: 0.9105 - val_loss: 0.3407 - val_precision: 0.9225 - val_recall: 0.8953\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 150ms/step - AUC: 0.9774 - accuracy: 0.9288 - loss: 0.3204 - precision: 0.9413 - recall: 0.9201 - val_AUC: 0.9687 - val_accuracy: 0.9119 - val_loss: 0.3397 - val_precision: 0.9244 - val_recall: 0.8963\n",
      "Penalized F1: 0.8848, Best F1: 0.9091, P: 0.9240, R: 0.8947\n",
      "Last Epoch --> Train Loss: 0.3204175531864166 | Val Loss: 0.33965033292770386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 16:19:10,943] Trial 6 finished with value: 0.8848494019012861 and parameters: {'lr_stage1': 0.0002232186358909881, 'lr_stage2': 4.1743788104585454e-05, 'weight_decay': 0.00033124805000197714, 'label_smoothing': 0.1, 'dropout_rate': 0.15000000000000002}. Best is trial 5 with value: 0.8859530084192327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4265.82 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 8/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 138ms/step - AUC: 0.8610 - accuracy: 0.7818 - loss: 0.4867 - precision: 0.7987 - recall: 0.7745 - val_AUC: 0.9234 - val_accuracy: 0.8343 - val_loss: 0.4066 - val_precision: 0.9523 - val_recall: 0.7022\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9113 - accuracy: 0.8334 - loss: 0.3974 - precision: 0.8587 - recall: 0.8126 - val_AUC: 0.9364 - val_accuracy: 0.8674 - val_loss: 0.3758 - val_precision: 0.8573 - val_recall: 0.8801\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 134ms/step - AUC: 0.9238 - accuracy: 0.8512 - loss: 0.3731 - precision: 0.8736 - recall: 0.8337 - val_AUC: 0.9411 - val_accuracy: 0.8400 - val_loss: 0.3856 - val_precision: 0.9624 - val_recall: 0.7060\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 151ms/step - AUC: 0.9423 - accuracy: 0.8737 - loss: 0.3323 - precision: 0.8985 - recall: 0.8529 - val_AUC: 0.9509 - val_accuracy: 0.8902 - val_loss: 0.3127 - val_precision: 0.9099 - val_recall: 0.8649\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9515 - accuracy: 0.8922 - loss: 0.3086 - precision: 0.9114 - recall: 0.8776 - val_AUC: 0.9561 - val_accuracy: 0.8883 - val_loss: 0.3064 - val_precision: 0.9463 - val_recall: 0.8221\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9592 - accuracy: 0.8994 - loss: 0.2888 - precision: 0.9215 - recall: 0.8812 - val_AUC: 0.9589 - val_accuracy: 0.9044 - val_loss: 0.2894 - val_precision: 0.9133 - val_recall: 0.8925\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9639 - accuracy: 0.9057 - loss: 0.2760 - precision: 0.9239 - recall: 0.8919 - val_AUC: 0.9610 - val_accuracy: 0.9001 - val_loss: 0.2864 - val_precision: 0.9430 - val_recall: 0.8506\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9650 - accuracy: 0.9098 - loss: 0.2718 - precision: 0.9266 - recall: 0.8973 - val_AUC: 0.9618 - val_accuracy: 0.9086 - val_loss: 0.2784 - val_precision: 0.9307 - val_recall: 0.8820\n",
      "Penalized F1: 0.8707, Best F1: 0.9010, P: 0.9290, R: 0.8750\n",
      "Last Epoch --> Train Loss: 0.27180448174476624 | Val Loss: 0.27839505672454834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 16:34:48,535] Trial 7 finished with value: 0.8706924489092092 and parameters: {'lr_stage1': 0.0003709948110182192, 'lr_stage2': 1.0136508746583104e-05, 'weight_decay': 0.0002962550087021392, 'label_smoothing': 0.025, 'dropout_rate': 0.4}. Best is trial 5 with value: 0.8859530084192327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4493.32 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 9/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 138ms/step - AUC: 0.8464 - accuracy: 0.7710 - loss: 0.5389 - precision: 0.7862 - recall: 0.7673 - val_AUC: 0.9163 - val_accuracy: 0.7789 - val_loss: 0.5267 - val_precision: 0.9756 - val_recall: 0.5699\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9000 - accuracy: 0.8265 - loss: 0.4715 - precision: 0.8496 - recall: 0.8086 - val_AUC: 0.9326 - val_accuracy: 0.8537 - val_loss: 0.4360 - val_precision: 0.9324 - val_recall: 0.7612\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 135ms/step - AUC: 0.9193 - accuracy: 0.8480 - loss: 0.4441 - precision: 0.8683 - recall: 0.8335 - val_AUC: 0.9356 - val_accuracy: 0.8698 - val_loss: 0.4223 - val_precision: 0.9025 - val_recall: 0.8278\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 152ms/step - AUC: 0.9323 - accuracy: 0.8614 - loss: 0.4228 - precision: 0.8790 - recall: 0.8499 - val_AUC: 0.9545 - val_accuracy: 0.8887 - val_loss: 0.3843 - val_precision: 0.9406 - val_recall: 0.8287\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9528 - accuracy: 0.8901 - loss: 0.3850 - precision: 0.9073 - recall: 0.8778 - val_AUC: 0.9606 - val_accuracy: 0.9001 - val_loss: 0.3662 - val_precision: 0.9242 - val_recall: 0.8706\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 151ms/step - AUC: 0.9607 - accuracy: 0.8983 - loss: 0.3695 - precision: 0.9139 - recall: 0.8875 - val_AUC: 0.9628 - val_accuracy: 0.9025 - val_loss: 0.3611 - val_precision: 0.9324 - val_recall: 0.8668\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9669 - accuracy: 0.9105 - loss: 0.3539 - precision: 0.9254 - recall: 0.9001 - val_AUC: 0.9654 - val_accuracy: 0.9077 - val_loss: 0.3587 - val_precision: 0.9458 - val_recall: 0.8639\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9698 - accuracy: 0.9139 - loss: 0.3465 - precision: 0.9293 - recall: 0.9028 - val_AUC: 0.9662 - val_accuracy: 0.9124 - val_loss: 0.3495 - val_precision: 0.9304 - val_recall: 0.8906\n",
      "Penalized F1: 0.8711, Best F1: 0.9038, P: 0.9362, R: 0.8738\n",
      "Last Epoch --> Train Loss: 0.3465293049812317 | Val Loss: 0.3495272696018219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 16:50:29,730] Trial 8 finished with value: 0.8711098774548722 and parameters: {'lr_stage1': 0.00012118952411898924, 'lr_stage2': 3.0644043290503086e-05, 'weight_decay': 6.226732991769637e-05, 'label_smoothing': 0.1, 'dropout_rate': 0.5}. Best is trial 5 with value: 0.8859530084192327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4633.45 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 10/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 137ms/step - AUC: 0.8968 - accuracy: 0.8241 - loss: 0.4745 - precision: 0.8460 - recall: 0.8079 - val_AUC: 0.9304 - val_accuracy: 0.8646 - val_loss: 0.4221 - val_precision: 0.8891 - val_recall: 0.8316\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 133ms/step - AUC: 0.9258 - accuracy: 0.8518 - loss: 0.4311 - precision: 0.8715 - recall: 0.8382 - val_AUC: 0.9414 - val_accuracy: 0.8769 - val_loss: 0.4020 - val_precision: 0.8920 - val_recall: 0.8563\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 133ms/step - AUC: 0.9391 - accuracy: 0.8682 - loss: 0.4095 - precision: 0.8886 - recall: 0.8530 - val_AUC: 0.9402 - val_accuracy: 0.8485 - val_loss: 0.4305 - val_precision: 0.8105 - val_recall: 0.9077\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 151ms/step - AUC: 0.9469 - accuracy: 0.8800 - loss: 0.3945 - precision: 0.9001 - recall: 0.8648 - val_AUC: 0.9534 - val_accuracy: 0.8864 - val_loss: 0.3900 - val_precision: 0.9451 - val_recall: 0.8192\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 148ms/step - AUC: 0.9581 - accuracy: 0.8953 - loss: 0.3711 - precision: 0.9091 - recall: 0.8870 - val_AUC: 0.9621 - val_accuracy: 0.8996 - val_loss: 0.3680 - val_precision: 0.9477 - val_recall: 0.8449\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9656 - accuracy: 0.9095 - loss: 0.3530 - precision: 0.9244 - recall: 0.8992 - val_AUC: 0.9641 - val_accuracy: 0.9067 - val_loss: 0.3563 - val_precision: 0.9420 - val_recall: 0.8658\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9724 - accuracy: 0.9220 - loss: 0.3365 - precision: 0.9357 - recall: 0.9121 - val_AUC: 0.9664 - val_accuracy: 0.9124 - val_loss: 0.3475 - val_precision: 0.9418 - val_recall: 0.8782\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9773 - accuracy: 0.9251 - loss: 0.3244 - precision: 0.9376 - recall: 0.9168 - val_AUC: 0.9656 - val_accuracy: 0.9105 - val_loss: 0.3489 - val_precision: 0.9081 - val_recall: 0.9125\n",
      "Penalized F1: 0.8724, Best F1: 0.9072, P: 0.9307, R: 0.8855\n",
      "Last Epoch --> Train Loss: 0.3244267404079437 | Val Loss: 0.3489167392253876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 17:06:05,087] Trial 9 finished with value: 0.8723533325051929 and parameters: {'lr_stage1': 0.00010423308048352459, 'lr_stage2': 3.426818279242055e-05, 'weight_decay': 0.00045582404612218855, 'label_smoothing': 0.1, 'dropout_rate': 0.15000000000000002}. Best is trial 5 with value: 0.8859530084192327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4757.72 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 11/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 139ms/step - AUC: 0.8779 - accuracy: 0.8034 - loss: 0.4871 - precision: 0.8247 - recall: 0.7889 - val_AUC: 0.9253 - val_accuracy: 0.7865 - val_loss: 0.4813 - val_precision: 0.7203 - val_recall: 0.9334\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 135ms/step - AUC: 0.9180 - accuracy: 0.8487 - loss: 0.4248 - precision: 0.8712 - recall: 0.8315 - val_AUC: 0.9372 - val_accuracy: 0.8674 - val_loss: 0.3927 - val_precision: 0.9186 - val_recall: 0.8049\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 134ms/step - AUC: 0.9293 - accuracy: 0.8613 - loss: 0.4046 - precision: 0.8816 - recall: 0.8462 - val_AUC: 0.9423 - val_accuracy: 0.8670 - val_loss: 0.4015 - val_precision: 0.9365 - val_recall: 0.7859\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 152ms/step - AUC: 0.9463 - accuracy: 0.8793 - loss: 0.3730 - precision: 0.8997 - recall: 0.8636 - val_AUC: 0.9541 - val_accuracy: 0.8906 - val_loss: 0.3630 - val_precision: 0.8853 - val_recall: 0.8963\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9568 - accuracy: 0.8964 - loss: 0.3490 - precision: 0.9139 - recall: 0.8836 - val_AUC: 0.9597 - val_accuracy: 0.8991 - val_loss: 0.3394 - val_precision: 0.9284 - val_recall: 0.8639\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9640 - accuracy: 0.9068 - loss: 0.3329 - precision: 0.9208 - recall: 0.8976 - val_AUC: 0.9631 - val_accuracy: 0.9105 - val_loss: 0.3303 - val_precision: 0.9176 - val_recall: 0.9010\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 148ms/step - AUC: 0.9688 - accuracy: 0.9154 - loss: 0.3204 - precision: 0.9309 - recall: 0.9041 - val_AUC: 0.9652 - val_accuracy: 0.9110 - val_loss: 0.3279 - val_precision: 0.9113 - val_recall: 0.9096\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 147ms/step - AUC: 0.9719 - accuracy: 0.9190 - loss: 0.3111 - precision: 0.9357 - recall: 0.9061 - val_AUC: 0.9655 - val_accuracy: 0.9072 - val_loss: 0.3239 - val_precision: 0.9130 - val_recall: 0.8991\n",
      "Penalized F1: 0.8968, Best F1: 0.9086, P: 0.9140, R: 0.9033\n",
      "Last Epoch --> Train Loss: 0.3110508322715759 | Val Loss: 0.3239439129829407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 17:21:43,815] Trial 10 finished with value: 0.8967769437770365 and parameters: {'lr_stage1': 0.0008824906998131688, 'lr_stage2': 2.0474913006882903e-05, 'weight_decay': 1.0450737163016266e-05, 'label_smoothing': 0.075, 'dropout_rate': 0.25}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4804.52 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 12/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 138ms/step - AUC: 0.8773 - accuracy: 0.7989 - loss: 0.4913 - precision: 0.8189 - recall: 0.7861 - val_AUC: 0.9327 - val_accuracy: 0.8461 - val_loss: 0.4349 - val_precision: 0.8124 - val_recall: 0.8982\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 134ms/step - AUC: 0.9198 - accuracy: 0.8536 - loss: 0.4205 - precision: 0.8766 - recall: 0.8354 - val_AUC: 0.9388 - val_accuracy: 0.8617 - val_loss: 0.3966 - val_precision: 0.9269 - val_recall: 0.7840\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9284 - accuracy: 0.8625 - loss: 0.4070 - precision: 0.8800 - recall: 0.8512 - val_AUC: 0.9371 - val_accuracy: 0.8712 - val_loss: 0.3901 - val_precision: 0.8727 - val_recall: 0.8677\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 156ms/step - AUC: 0.9459 - accuracy: 0.8846 - loss: 0.3714 - precision: 0.9035 - recall: 0.8706 - val_AUC: 0.9563 - val_accuracy: 0.8939 - val_loss: 0.3520 - val_precision: 0.9339 - val_recall: 0.8468\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9569 - accuracy: 0.8920 - loss: 0.3500 - precision: 0.9087 - recall: 0.8803 - val_AUC: 0.9585 - val_accuracy: 0.8778 - val_loss: 0.3882 - val_precision: 0.9692 - val_recall: 0.7793\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 150ms/step - AUC: 0.9628 - accuracy: 0.9078 - loss: 0.3337 - precision: 0.9249 - recall: 0.8949 - val_AUC: 0.9603 - val_accuracy: 0.8840 - val_loss: 0.3719 - val_precision: 0.9654 - val_recall: 0.7954\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 150ms/step - AUC: 0.9665 - accuracy: 0.9095 - loss: 0.3261 - precision: 0.9233 - recall: 0.9003 - val_AUC: 0.9625 - val_accuracy: 0.8887 - val_loss: 0.3603 - val_precision: 0.9595 - val_recall: 0.8107\n",
      "Penalized F1: 0.7697, Best F1: 0.8716, P: 0.9647, R: 0.7951\n",
      "Last Epoch --> Train Loss: 0.3260681927204132 | Val Loss: 0.36031556129455566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 17:35:34,199] Trial 11 finished with value: 0.769734047998656 and parameters: {'lr_stage1': 0.0009727585628338528, 'lr_stage2': 2.0417655748679923e-05, 'weight_decay': 1.3565328529654705e-05, 'label_smoothing': 0.075, 'dropout_rate': 0.25}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 4988.34 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 13/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 139ms/step - AUC: 0.8926 - accuracy: 0.8124 - loss: 0.4656 - precision: 0.8377 - recall: 0.7919 - val_AUC: 0.9364 - val_accuracy: 0.8603 - val_loss: 0.4011 - val_precision: 0.9276 - val_recall: 0.7802\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9292 - accuracy: 0.8596 - loss: 0.4046 - precision: 0.8799 - recall: 0.8443 - val_AUC: 0.9423 - val_accuracy: 0.8731 - val_loss: 0.3835 - val_precision: 0.8628 - val_recall: 0.8858\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9376 - accuracy: 0.8701 - loss: 0.3874 - precision: 0.8928 - recall: 0.8521 - val_AUC: 0.9467 - val_accuracy: 0.8854 - val_loss: 0.3696 - val_precision: 0.9107 - val_recall: 0.8535\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 152ms/step - AUC: 0.9493 - accuracy: 0.8878 - loss: 0.3633 - precision: 0.9062 - recall: 0.8743 - val_AUC: 0.9575 - val_accuracy: 0.8991 - val_loss: 0.3426 - val_precision: 0.9284 - val_recall: 0.8639\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 150ms/step - AUC: 0.9605 - accuracy: 0.9038 - loss: 0.3379 - precision: 0.9256 - recall: 0.8857 - val_AUC: 0.9628 - val_accuracy: 0.9039 - val_loss: 0.3324 - val_precision: 0.9061 - val_recall: 0.9001\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9654 - accuracy: 0.9092 - loss: 0.3265 - precision: 0.9308 - recall: 0.8913 - val_AUC: 0.9637 - val_accuracy: 0.8935 - val_loss: 0.3487 - val_precision: 0.8668 - val_recall: 0.9286\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 150ms/step - AUC: 0.9701 - accuracy: 0.9163 - loss: 0.3134 - precision: 0.9313 - recall: 0.9056 - val_AUC: 0.9657 - val_accuracy: 0.9039 - val_loss: 0.3374 - val_precision: 0.9520 - val_recall: 0.8497\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 150ms/step - AUC: 0.9729 - accuracy: 0.9231 - loss: 0.3060 - precision: 0.9403 - recall: 0.9095 - val_AUC: 0.9673 - val_accuracy: 0.9134 - val_loss: 0.3172 - val_precision: 0.9222 - val_recall: 0.9020\n",
      "Penalized F1: 0.8864, Best F1: 0.9022, P: 0.9137, R: 0.8934\n",
      "Last Epoch --> Train Loss: 0.30597639083862305 | Val Loss: 0.31722524762153625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 17:51:20,339] Trial 12 finished with value: 0.8864488389472452 and parameters: {'lr_stage1': 0.0006054619184372066, 'lr_stage2': 2.1973538224188875e-05, 'weight_decay': 1.033286319781919e-06, 'label_smoothing': 0.075, 'dropout_rate': 0.1}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 5122.33 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 14/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - AUC: 0.8365 - accuracy: 0.7608 - loss: 0.5500 - precision: 0.7771 - recall: 0.7562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 17:52:55.991557: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 139ms/step - AUC: 0.8767 - accuracy: 0.7993 - loss: 0.4907 - precision: 0.8180 - recall: 0.7889 - val_AUC: 0.9330 - val_accuracy: 0.8385 - val_loss: 0.4243 - val_precision: 0.9415 - val_recall: 0.7203\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9204 - accuracy: 0.8512 - loss: 0.4211 - precision: 0.8741 - recall: 0.8332 - val_AUC: 0.9388 - val_accuracy: 0.8802 - val_loss: 0.4026 - val_precision: 0.8851 - val_recall: 0.8725\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 135ms/step - AUC: 0.9289 - accuracy: 0.8651 - loss: 0.4053 - precision: 0.8870 - recall: 0.8476 - val_AUC: 0.9425 - val_accuracy: 0.8788 - val_loss: 0.3980 - val_precision: 0.9233 - val_recall: 0.8249\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 153ms/step - AUC: 0.9467 - accuracy: 0.8845 - loss: 0.3710 - precision: 0.9055 - recall: 0.8677 - val_AUC: 0.9519 - val_accuracy: 0.8707 - val_loss: 0.3846 - val_precision: 0.9523 - val_recall: 0.7793\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9565 - accuracy: 0.8933 - loss: 0.3507 - precision: 0.9125 - recall: 0.8784 - val_AUC: 0.9608 - val_accuracy: 0.8930 - val_loss: 0.3595 - val_precision: 0.9619 - val_recall: 0.8173\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 148ms/step - AUC: 0.9631 - accuracy: 0.9042 - loss: 0.3345 - precision: 0.9230 - recall: 0.8894 - val_AUC: 0.9622 - val_accuracy: 0.9029 - val_loss: 0.3446 - val_precision: 0.8859 - val_recall: 0.9239\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 149ms/step - AUC: 0.9680 - accuracy: 0.9141 - loss: 0.3214 - precision: 0.9315 - recall: 0.9007 - val_AUC: 0.9656 - val_accuracy: 0.9100 - val_loss: 0.3241 - val_precision: 0.9176 - val_recall: 0.9001\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 148ms/step - AUC: 0.9695 - accuracy: 0.9166 - loss: 0.3168 - precision: 0.9302 - recall: 0.9073 - val_AUC: 0.9665 - val_accuracy: 0.8991 - val_loss: 0.3404 - val_precision: 0.9645 - val_recall: 0.8278\n",
      "Penalized F1: 0.8702, Best F1: 0.9014, P: 0.9227, R: 0.8839\n",
      "Last Epoch --> Train Loss: 0.31680187582969666 | Val Loss: 0.34038597345352173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 18:07:07,683] Trial 13 finished with value: 0.870228842881795 and parameters: {'lr_stage1': 0.0006259097298688021, 'lr_stage2': 2.0316426715710147e-05, 'weight_decay': 1.3307053970122303e-06, 'label_smoothing': 0.075, 'dropout_rate': 0.30000000000000004}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 5247.07 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 15/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 139ms/step - AUC: 0.8877 - accuracy: 0.8113 - loss: 0.4705 - precision: 0.8343 - recall: 0.7940 - val_AUC: 0.9317 - val_accuracy: 0.8513 - val_loss: 0.4089 - val_precision: 0.9250 - val_recall: 0.7631\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 134ms/step - AUC: 0.9298 - accuracy: 0.8521 - loss: 0.4037 - precision: 0.8743 - recall: 0.8350 - val_AUC: 0.9424 - val_accuracy: 0.8570 - val_loss: 0.4100 - val_precision: 0.8226 - val_recall: 0.9087\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 135ms/step - AUC: 0.9376 - accuracy: 0.8715 - loss: 0.3894 - precision: 0.8881 - recall: 0.8608 - val_AUC: 0.9479 - val_accuracy: 0.8859 - val_loss: 0.3704 - val_precision: 0.9026 - val_recall: 0.8639\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 156ms/step - AUC: 0.9462 - accuracy: 0.8788 - loss: 0.3713 - precision: 0.9013 - recall: 0.8605 - val_AUC: 0.9571 - val_accuracy: 0.8849 - val_loss: 0.3725 - val_precision: 0.9644 - val_recall: 0.7983\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 160ms/step - AUC: 0.9600 - accuracy: 0.8974 - loss: 0.3408 - precision: 0.9182 - recall: 0.8805 - val_AUC: 0.9612 - val_accuracy: 0.8778 - val_loss: 0.3834 - val_precision: 0.9703 - val_recall: 0.7783\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 156ms/step - AUC: 0.9651 - accuracy: 0.9083 - loss: 0.3274 - precision: 0.9275 - recall: 0.8931 - val_AUC: 0.9643 - val_accuracy: 0.9086 - val_loss: 0.3280 - val_precision: 0.9405 - val_recall: 0.8716\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 157ms/step - AUC: 0.9705 - accuracy: 0.9174 - loss: 0.3132 - precision: 0.9341 - recall: 0.9045 - val_AUC: 0.9663 - val_accuracy: 0.9110 - val_loss: 0.3226 - val_precision: 0.9106 - val_recall: 0.9106\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 155ms/step - AUC: 0.9773 - accuracy: 0.9288 - loss: 0.2944 - precision: 0.9443 - recall: 0.9168 - val_AUC: 0.9679 - val_accuracy: 0.9119 - val_loss: 0.3190 - val_precision: 0.9069 - val_recall: 0.9172\n",
      "Penalized F1: 0.8870, Best F1: 0.9091, P: 0.9193, R: 0.8998\n",
      "Last Epoch --> Train Loss: 0.2944200038909912 | Val Loss: 0.3190404772758484\n",
      "ğŸ§¹ RAM Cleaned. Current usage: 5405.83 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 18:23:52,064] Trial 14 finished with value: 0.8870213007309236 and parameters: {'lr_stage1': 0.0005150301439755446, 'lr_stage2': 2.852198656275729e-05, 'weight_decay': 9.162884230838277e-06, 'label_smoothing': 0.075, 'dropout_rate': 0.1}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================================================================================\n",
      "Trial 16/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 147ms/step - AUC: 0.8838 - accuracy: 0.8086 - loss: 0.4795 - precision: 0.8284 - recall: 0.7962 - val_AUC: 0.9296 - val_accuracy: 0.8665 - val_loss: 0.4053 - val_precision: 0.9052 - val_recall: 0.8173\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 140ms/step - AUC: 0.9221 - accuracy: 0.8491 - loss: 0.4183 - precision: 0.8679 - recall: 0.8365 - val_AUC: 0.9378 - val_accuracy: 0.8674 - val_loss: 0.3973 - val_precision: 0.9114 - val_recall: 0.8126\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 140ms/step - AUC: 0.9311 - accuracy: 0.8622 - loss: 0.4022 - precision: 0.8826 - recall: 0.8472 - val_AUC: 0.9427 - val_accuracy: 0.8674 - val_loss: 0.3911 - val_precision: 0.9327 - val_recall: 0.7907\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 160ms/step - AUC: 0.9452 - accuracy: 0.8800 - loss: 0.3743 - precision: 0.8980 - recall: 0.8672 - val_AUC: 0.9563 - val_accuracy: 0.8892 - val_loss: 0.3570 - val_precision: 0.9369 - val_recall: 0.8335\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 153ms/step - AUC: 0.9581 - accuracy: 0.8972 - loss: 0.3470 - precision: 0.9153 - recall: 0.8836 - val_AUC: 0.9603 - val_accuracy: 0.9010 - val_loss: 0.3393 - val_precision: 0.9287 - val_recall: 0.8677\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 158ms/step - AUC: 0.9667 - accuracy: 0.9089 - loss: 0.3242 - precision: 0.9251 - recall: 0.8969 - val_AUC: 0.9642 - val_accuracy: 0.9077 - val_loss: 0.3301 - val_precision: 0.9306 - val_recall: 0.8801\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 158ms/step - AUC: 0.9704 - accuracy: 0.9158 - loss: 0.3139 - precision: 0.9320 - recall: 0.9037 - val_AUC: 0.9644 - val_accuracy: 0.9105 - val_loss: 0.3253 - val_precision: 0.9160 - val_recall: 0.9029\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 157ms/step - AUC: 0.9748 - accuracy: 0.9262 - loss: 0.3007 - precision: 0.9404 - recall: 0.9158 - val_AUC: 0.9665 - val_accuracy: 0.9148 - val_loss: 0.3193 - val_precision: 0.9232 - val_recall: 0.9039\n",
      "Penalized F1: 0.8860, Best F1: 0.9092, P: 0.9233, R: 0.8957\n",
      "Last Epoch --> Train Loss: 0.30066177248954773 | Val Loss: 0.31930628418922424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 18:41:17,636] Trial 15 finished with value: 0.886048499156073 and parameters: {'lr_stage1': 0.00045245484656908483, 'lr_stage2': 2.910892474006726e-05, 'weight_decay': 1.1759814162223408e-05, 'label_smoothing': 0.075, 'dropout_rate': 0.25}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 5498.88 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 17/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 153ms/step - AUC: 0.8750 - accuracy: 0.8034 - loss: 0.4945 - precision: 0.8218 - recall: 0.7931 - val_AUC: 0.9208 - val_accuracy: 0.8258 - val_loss: 0.4489 - val_precision: 0.7872 - val_recall: 0.8906\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 139ms/step - AUC: 0.9137 - accuracy: 0.8397 - loss: 0.4331 - precision: 0.8605 - recall: 0.8246 - val_AUC: 0.9301 - val_accuracy: 0.8116 - val_loss: 0.4501 - val_precision: 0.7549 - val_recall: 0.9201\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 143ms/step - AUC: 0.9263 - accuracy: 0.8537 - loss: 0.4109 - precision: 0.8755 - recall: 0.8372 - val_AUC: 0.9397 - val_accuracy: 0.8741 - val_loss: 0.3940 - val_precision: 0.8822 - val_recall: 0.8620\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 162ms/step - AUC: 0.9398 - accuracy: 0.8704 - loss: 0.3862 - precision: 0.8933 - recall: 0.8521 - val_AUC: 0.9567 - val_accuracy: 0.8698 - val_loss: 0.3954 - val_precision: 0.8207 - val_recall: 0.9448\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 155ms/step - AUC: 0.9540 - accuracy: 0.8963 - loss: 0.3553 - precision: 0.9131 - recall: 0.8842 - val_AUC: 0.9582 - val_accuracy: 0.8660 - val_loss: 0.4097 - val_precision: 0.9788 - val_recall: 0.7469\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 179ms/step - AUC: 0.9629 - accuracy: 0.9073 - loss: 0.3330 - precision: 0.9231 - recall: 0.8961 - val_AUC: 0.9648 - val_accuracy: 0.9091 - val_loss: 0.3258 - val_precision: 0.9274 - val_recall: 0.8868\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 153ms/step - AUC: 0.9697 - accuracy: 0.9147 - loss: 0.3148 - precision: 0.9308 - recall: 0.9029 - val_AUC: 0.9686 - val_accuracy: 0.9148 - val_loss: 0.3146 - val_precision: 0.9216 - val_recall: 0.9058\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 154ms/step - AUC: 0.9754 - accuracy: 0.9272 - loss: 0.2973 - precision: 0.9402 - recall: 0.9180 - val_AUC: 0.9671 - val_accuracy: 0.9119 - val_loss: 0.3199 - val_precision: 0.9454 - val_recall: 0.8735\n",
      "Penalized F1: 0.8767, Best F1: 0.9094, P: 0.9315, R: 0.8887\n",
      "Last Epoch --> Train Loss: 0.2972820997238159 | Val Loss: 0.3198719620704651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 18:59:14,985] Trial 16 finished with value: 0.8767338985895474 and parameters: {'lr_stage1': 0.0004926162705873095, 'lr_stage2': 4.8245880641034965e-05, 'weight_decay': 1.3790886823784234e-05, 'label_smoothing': 0.075, 'dropout_rate': 0.35}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 5583.41 MB\n",
      "====================================================================================================================================================================================\n",
      "Trial 18/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 147ms/step - AUC: 0.8844 - accuracy: 0.8049 - loss: 0.4643 - precision: 0.8249 - recall: 0.7923 - val_AUC: 0.9287 - val_accuracy: 0.8456 - val_loss: 0.4027 - val_precision: 0.8177 - val_recall: 0.8877\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 139ms/step - AUC: 0.9214 - accuracy: 0.8529 - loss: 0.3986 - precision: 0.8768 - recall: 0.8340 - val_AUC: 0.9368 - val_accuracy: 0.8532 - val_loss: 0.3814 - val_precision: 0.8282 - val_recall: 0.8896\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 142ms/step - AUC: 0.9302 - accuracy: 0.8602 - loss: 0.3813 - precision: 0.8838 - recall: 0.8411 - val_AUC: 0.9407 - val_accuracy: 0.8759 - val_loss: 0.3632 - val_precision: 0.9192 - val_recall: 0.8230\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 162ms/step - AUC: 0.9450 - accuracy: 0.8785 - loss: 0.3525 - precision: 0.9013 - recall: 0.8599 - val_AUC: 0.9540 - val_accuracy: 0.8830 - val_loss: 0.3401 - val_precision: 0.9398 - val_recall: 0.8173\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 153ms/step - AUC: 0.9584 - accuracy: 0.8975 - loss: 0.3192 - precision: 0.9193 - recall: 0.8797 - val_AUC: 0.9576 - val_accuracy: 0.8977 - val_loss: 0.3218 - val_precision: 0.8980 - val_recall: 0.8963\n",
      "Epoch 6/8\n",
      "\u001b[1m789/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - AUC: 0.9622 - accuracy: 0.9058 - loss: 0.3076 - precision: 0.9230 - recall: 0.8931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:11:21.718327: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 157ms/step - AUC: 0.9616 - accuracy: 0.9010 - loss: 0.3112 - precision: 0.9197 - recall: 0.8867 - val_AUC: 0.9615 - val_accuracy: 0.9025 - val_loss: 0.3090 - val_precision: 0.9212 - val_recall: 0.8792\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 155ms/step - AUC: 0.9664 - accuracy: 0.9103 - loss: 0.2970 - precision: 0.9329 - recall: 0.8913 - val_AUC: 0.9618 - val_accuracy: 0.9010 - val_loss: 0.3092 - val_precision: 0.9278 - val_recall: 0.8687\n",
      "Epoch 8/8\n",
      "\u001b[1m789/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - AUC: 0.9694 - accuracy: 0.9229 - loss: 0.2857 - precision: 0.9440 - recall: 0.9058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:15:25.790550: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 153ms/step - AUC: 0.9698 - accuracy: 0.9193 - loss: 0.2865 - precision: 0.9382 - recall: 0.9040 - val_AUC: 0.9652 - val_accuracy: 0.9086 - val_loss: 0.2982 - val_precision: 0.9206 - val_recall: 0.8934\n",
      "Penalized F1: 0.8740, Best F1: 0.9013, P: 0.9232, R: 0.8804\n",
      "Last Epoch --> Train Loss: 0.2865269184112549 | Val Loss: 0.29819977283477783\n",
      "ğŸ§¹ RAM Cleaned. Current usage: 5793.29 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 19:16:18,538] Trial 17 finished with value: 0.8740387265074386 and parameters: {'lr_stage1': 0.0008481613100519265, 'lr_stage2': 1.564495893548871e-05, 'weight_decay': 5.331398803455113e-06, 'label_smoothing': 0.05, 'dropout_rate': 0.2}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================================================================================\n",
      "Trial 19/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 144ms/step - AUC: 0.8824 - accuracy: 0.8056 - loss: 0.4817 - precision: 0.8260 - recall: 0.7921 - val_AUC: 0.9292 - val_accuracy: 0.8513 - val_loss: 0.4170 - val_precision: 0.8323 - val_recall: 0.8782\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 136ms/step - AUC: 0.9240 - accuracy: 0.8520 - loss: 0.4157 - precision: 0.8720 - recall: 0.8379 - val_AUC: 0.9412 - val_accuracy: 0.8523 - val_loss: 0.4166 - val_precision: 0.8155 - val_recall: 0.9087\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 179ms/step - AUC: 0.9301 - accuracy: 0.8561 - loss: 0.4045 - precision: 0.8742 - recall: 0.8442 - val_AUC: 0.9426 - val_accuracy: 0.8594 - val_loss: 0.3997 - val_precision: 0.8273 - val_recall: 0.9068\n",
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 154ms/step - AUC: 0.9470 - accuracy: 0.8800 - loss: 0.3698 - precision: 0.9024 - recall: 0.8620 - val_AUC: 0.9492 - val_accuracy: 0.8665 - val_loss: 0.3937 - val_precision: 0.9508 - val_recall: 0.7716\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 152ms/step - AUC: 0.9538 - accuracy: 0.8912 - loss: 0.3550 - precision: 0.9112 - recall: 0.8758 - val_AUC: 0.9573 - val_accuracy: 0.8963 - val_loss: 0.3457 - val_precision: 0.9236 - val_recall: 0.8630\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - AUC: 0.9607 - accuracy: 0.9082 - loss: 0.3378 - precision: 0.9298 - recall: 0.8905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:28:39.560622: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 153ms/step - AUC: 0.9606 - accuracy: 0.9057 - loss: 0.3394 - precision: 0.9270 - recall: 0.8881 - val_AUC: 0.9587 - val_accuracy: 0.8944 - val_loss: 0.3518 - val_precision: 0.8819 - val_recall: 0.9096\n",
      "Epoch 7/8\n",
      "\u001b[1m792/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - AUC: 0.9632 - accuracy: 0.9083 - loss: 0.3316 - precision: 0.9303 - recall: 0.8930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:30:42.984733: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 155ms/step - AUC: 0.9644 - accuracy: 0.9067 - loss: 0.3308 - precision: 0.9267 - recall: 0.8906 - val_AUC: 0.9607 - val_accuracy: 0.9010 - val_loss: 0.3367 - val_precision: 0.9103 - val_recall: 0.8887\n",
      "Epoch 8/8\n",
      "\u001b[1m792/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - AUC: 0.9655 - accuracy: 0.9144 - loss: 0.3233 - precision: 0.9347 - recall: 0.8969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:32:43.411365: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 153ms/step - AUC: 0.9673 - accuracy: 0.9119 - loss: 0.3229 - precision: 0.9304 - recall: 0.8973 - val_AUC: 0.9617 - val_accuracy: 0.9044 - val_loss: 0.3336 - val_precision: 0.9284 - val_recall: 0.8754\n",
      "Penalized F1: 0.8855, Best F1: 0.8987, P: 0.9069, R: 0.8912\n",
      "Last Epoch --> Train Loss: 0.32294055819511414 | Val Loss: 0.33360639214515686\n",
      "ğŸ§¹ RAM Cleaned. Current usage: 5894.10 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 19:33:36,083] Trial 18 finished with value: 0.8855074944711772 and parameters: {'lr_stage1': 0.0005274344666893341, 'lr_stage2': 9.55181610342451e-06, 'weight_decay': 2.727873832130904e-05, 'label_smoothing': 0.075, 'dropout_rate': 0.25}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================================================================================\n",
      "Trial 20/20 started...\n",
      "Epoch 1/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 145ms/step - AUC: 0.8609 - accuracy: 0.7866 - loss: 0.5171 - precision: 0.8055 - recall: 0.7761 - val_AUC: 0.9233 - val_accuracy: 0.8092 - val_loss: 0.4716 - val_precision: 0.9602 - val_recall: 0.6432\n",
      "Epoch 2/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - AUC: 0.9171 - accuracy: 0.8452 - loss: 0.4297 - precision: 0.8694 - recall: 0.8237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:37:20.596925: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 138ms/step - AUC: 0.9121 - accuracy: 0.8403 - loss: 0.4356 - precision: 0.8619 - recall: 0.8244 - val_AUC: 0.9370 - val_accuracy: 0.8622 - val_loss: 0.4119 - val_precision: 0.8430 - val_recall: 0.8887\n",
      "Epoch 3/3\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - AUC: 0.9252 - accuracy: 0.8599 - loss: 0.4123 - precision: 0.8808 - recall: 0.8485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:39:10.517473: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 139ms/step - AUC: 0.9207 - accuracy: 0.8532 - loss: 0.4206 - precision: 0.8747 - recall: 0.8372 - val_AUC: 0.9408 - val_accuracy: 0.8717 - val_loss: 0.3898 - val_precision: 0.9221 - val_recall: 0.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:39:38.171992: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - AUC: 0.9384 - accuracy: 0.8749 - loss: 0.3897 - precision: 0.8989 - recall: 0.8580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:41:35.868783: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:41:42.203803: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:41:42.203891: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:42:06.272399: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 162ms/step - AUC: 0.9383 - accuracy: 0.8756 - loss: 0.3898 - precision: 0.8966 - recall: 0.8593 - val_AUC: 0.9543 - val_accuracy: 0.8797 - val_loss: 0.3803 - val_precision: 0.9596 - val_recall: 0.7916\n",
      "Epoch 5/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - AUC: 0.9511 - accuracy: 0.8907 - loss: 0.3620 - precision: 0.9141 - recall: 0.8727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:43:42.782519: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:43:43.332677: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:43:43.332837: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:44:07.048304: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291712 bytes after encountering the first element of size 6291712 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 152ms/step - AUC: 0.9545 - accuracy: 0.8916 - loss: 0.3562 - precision: 0.9107 - recall: 0.8769 - val_AUC: 0.9589 - val_accuracy: 0.8991 - val_loss: 0.3412 - val_precision: 0.9157 - val_recall: 0.8782\n",
      "Epoch 6/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - AUC: 0.9609 - accuracy: 0.9062 - loss: 0.3388 - precision: 0.9212 - recall: 0.8954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:45:46.182143: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:45:46.923153: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:45:46.923384: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:46:11.754221: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 157ms/step - AUC: 0.9615 - accuracy: 0.9048 - loss: 0.3386 - precision: 0.9205 - recall: 0.8936 - val_AUC: 0.9625 - val_accuracy: 0.8996 - val_loss: 0.3359 - val_precision: 0.9365 - val_recall: 0.8563\n",
      "Epoch 7/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - AUC: 0.9677 - accuracy: 0.9097 - loss: 0.3247 - precision: 0.9240 - recall: 0.9026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:47:52.314149: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:47:52.991640: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:47:52.991781: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:48:16.856193: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291712 bytes after encountering the first element of size 6291712 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 158ms/step - AUC: 0.9667 - accuracy: 0.9105 - loss: 0.3257 - precision: 0.9236 - recall: 0.9022 - val_AUC: 0.9644 - val_accuracy: 0.9110 - val_loss: 0.3277 - val_precision: 0.9052 - val_recall: 0.9172\n",
      "Epoch 8/8\n",
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - AUC: 0.9696 - accuracy: 0.9182 - loss: 0.3138 - precision: 0.9345 - recall: 0.9084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 19:49:52.610284: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 6291488 bytes after encountering the first element of size 6291488 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:49:53.268841: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:49:53.268981: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2026-01-21 19:50:17.032488: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 8388864 bytes after encountering the first element of size 8388864 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m793/793\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 152ms/step - AUC: 0.9708 - accuracy: 0.9171 - loss: 0.3136 - precision: 0.9306 - recall: 0.9080 - val_AUC: 0.9634 - val_accuracy: 0.9072 - val_loss: 0.3265 - val_precision: 0.9146 - val_recall: 0.8972\n",
      "Penalized F1: 0.8831, Best F1: 0.9039, P: 0.9188, R: 0.8903\n",
      "Last Epoch --> Train Loss: 0.3135804831981659 | Val Loss: 0.3265308439731598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-21 19:50:50,768] Trial 19 finished with value: 0.8831489858358896 and parameters: {'lr_stage1': 0.0007220098212119819, 'lr_stage2': 2.6027633128633556e-05, 'weight_decay': 2.4975076576314156e-06, 'label_smoothing': 0.075, 'dropout_rate': 0.4}. Best is trial 10 with value: 0.8967769437770365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ RAM Cleaned. Current usage: 6032.79 MB\n"
     ]
    }
   ],
   "source": [
    "#### Create an Optuna study object to find the best hyperparameter configuration\n",
    "storage_dir = \"sqlite:///phase2_optimization/healthy_unhealthy-phase2_optimization.db\"\n",
    "study = optuna.create_study(\n",
    "    direction= 'maximize',\n",
    "    storage=storage_dir,\n",
    "    load_if_exists=True\n",
    ")\n",
    "# Start the optimization process over a fixed number of trials\n",
    "study.optimize(lambda trial: objective_optimization(\n",
    "    trial, config=OPTIMIZATION_CONFIG), \n",
    "    n_trials=OPTIMIZATION_CONFIG['opt_trials'], gc_after_trial= True)\n",
    "\n",
    "best_trial = study.best_trial \n",
    "best_hparams = best_trial.user_attrs.get(\"hparams\", None)\n",
    "\n",
    "# collect metadata to save \n",
    "metadata = { \n",
    "    \"best_trial_number\": int(best_trial.number), \n",
    "    \"best_value\": float(best_trial.value), \n",
    "    \"best_hparams\": best_hparams, \n",
    "    \"phase2_settings\": { \n",
    "        \"loss\": \"BinaryCrossentropy\", \n",
    "        \"optimizer\": \"AdamW\", \n",
    "        \"lr_schedules\": \"CosineDecay\", \n",
    "        \"warmup_epochs\": OPTIMIZATION_CONFIG[\"opt_warmup_epoch\"],\n",
    "        \"unfreeze_epochs\": OPTIMIZATION_CONFIG[\"opt_unfreeze_epoch\"],\n",
    "        \"unfreeze_layer\": OPTIMIZATION_CONFIG[\"unfreeze_layer\"],\n",
    "        \"trials\": OPTIMIZATION_CONFIG[\"opt_trials\"]\n",
    "    }, \n",
    "    \"timestamp\": time.time(), \n",
    "    \"seed\": SEED\n",
    "}\n",
    "\n",
    "metadata_dir = \"./phase2_optimization/healthy_unhealthy-best_hparams.json\"\n",
    "with open(metadata_dir, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
