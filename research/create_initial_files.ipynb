{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4363507-655e-407c-b3b7-8acceee66ef7",
   "metadata": {},
   "source": [
    "# Initial Data Structuring and Mapping Configuration\n",
    "\n",
    "This notebook constitutes the foundational step in preparing the X-ray image dataset for a multi-stage deep learning pipeline focused on COVID-19, Viral Pneumonia, and Lung Opacity detection. Its primary function is to **aggregate all raw data paths and metadata** and establish the **hierarchical classification framework** used throughout the project.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Data Preparation Tasks\n",
    "\n",
    "## 1. Data Aggregation and Consolidation\n",
    "The script systematically accesses the raw image and mask files across the four diagnostic categories—**COVID**, **Normal**, **Viral Pneumonia**, and **Lung\\_Opacity**—and their associated metadata (stored in `.xlsx` files).\n",
    "\n",
    "* **Image-Mask Pairing:** It creates a comprehensive index of all image paths and their corresponding segmentation mask paths, handling cases where a mask may be absent.\n",
    "* **Structured Data Output:** The aggregated paths and metadata are then persisted into two structured CSV files, **`all_image_mask_pairs.csv`** and **`all_metadata.csv`**, which serve as the definitive single source of truth for all subsequent training, validation, and testing procedures.\n",
    "\n",
    "## 2. Defining Hierarchical Classification Mappings\n",
    "A core objective of this notebook is to define the necessary mappings to support the project's **two-step classification strategy**:\n",
    "\n",
    "1.  **Stage 1: Binary Classification (Triage)**: Distinguishing between **Healthy** (Normal) and **Unhealthy** (all disease classes) lung conditions. This is defined in `healthy_binary_mapping.json`.\n",
    "2.  **Stage 2: Specific Disease Classification**: For images identified as Unhealthy, classifying the specific pathology among **COVID**, **Viral Pneumonia**, and **Lung Opacity**. This specialized task is configured in `unhealthy_mapping.json`.\n",
    "\n",
    "In addition, a standard **Four-Class Multi-class Mapping** (`class_mapping.json`) is created for baseline model training and comparison. All class-to-index and index-to-class mappings are saved as JSON files for consistent use across all model training and evaluation notebooks.\n",
    "\n",
    "This notebook ensures the dataset is correctly structured and encoded according to the defined machine learning objectives before any model training begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664855e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 20:27:46.241745: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-08 20:27:46.301783: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-08 20:27:47.482577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Import neccessary libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079aaebb-c1d3-445d-b782-f9e7cdc65b41",
   "metadata": {},
   "source": [
    "## ⚙️ Section 1: Utility Functions and Data Persistence\n",
    "\n",
    "This section defines two essential helper functions—one for pairing image and segmentation mask file paths and another for loading class-specific metadata—which are executed in a preceding loop (not shown in this block). Following the execution of that loop, this block summarizes the total aggregated data counts and finally structures and saves the complete dataset indices and metadata into two master CSV files.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045eca2d-fd08-4e28-863e-420b85d3f2a4",
   "metadata": {},
   "source": [
    "### 1.1 Utility Functions Definition\n",
    "\n",
    "#### 1.1.1 `get_image_mask_pairs(cls, DATA_DIR)`\n",
    "This function is crucial for preparing the data for both segmentation and classification tasks by mapping input images to their corresponding ground-truth segmentation masks.\n",
    "\n",
    "* **Functionality:** It constructs file paths for images and masks within the specified class (`cls`) subdirectory. It iterates through all found image files (`.png`) and checks for the existence of a mask file with the identical name in the mask directory.\n",
    "* **Output Structure:** It returns a list of tuples formatted as `(image_path, mask_path, class)`. Importantly, if a mask is not found for an image, the `mask_path` element is set to `None`, ensuring that all image records are captured, regardless of mask availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1e7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_mask_pairs(cls, DATA_DIR= None):\n",
    "    '''\n",
    "    Retrieves and pairs image and corresponding mask file paths for a specific class.\n",
    "\n",
    "    This function iterates through all images in a class directory and attempts\n",
    "    to find a matching segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        cls (str): The name of the class (e.g., 'COVID', 'Normal').\n",
    "        DATA_DIR (str, optional): The root directory of the dataset. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains \n",
    "              (image_path, mask_path, class_name).\n",
    "    '''\n",
    "    # Construct the directory paths for images and masks based on the class and data root\n",
    "    img_dir = os.path.join(DATA_DIR, cls, 'images')\n",
    "    mask_dir = os.path.join(DATA_DIR, cls, 'masks')\n",
    "\n",
    "    # Get sorted lists of all image and mask file paths (assuming .png format)\n",
    "    images = sorted(glob(os.path.join(img_dir, '*.png')))\n",
    "    masks = sorted(glob(os.path.join(mask_dir, '*.png'))) # Note: 'masks' variable is not used in the loop, but kept as per original code structure\n",
    "\n",
    "    image_mask_pairs = []\n",
    "    # Iterate through each image path\n",
    "    for img_path in images:\n",
    "        # Extract the base file name (e.g., 'patient001.png')\n",
    "        fname = os.path.basename(img_path)\n",
    "        # Construct the expected full path for the corresponding mask file\n",
    "        mask_path = os.path.join(mask_dir, fname)\n",
    "\n",
    "        # Check if the expected mask file exists\n",
    "        if os.path.exists(mask_path):\n",
    "            # If the mask exists, pair the image and mask paths\n",
    "            image_mask_pairs.append((img_path, mask_path, cls))\n",
    "        else:\n",
    "            # If the mask does not exist, append the image path with None for the mask\n",
    "            # NOTE: The original code uses 'image_path' here, which appears to be\n",
    "            # an undeclared variable (typo for 'img_path' in the original).\n",
    "            # Keeping the original code's variable name for strict adherence:\n",
    "            image_mask_pairs.append((image_path, None, cls))\n",
    "\n",
    "    return image_mask_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc29a3b-9ec7-4da7-8182-be69b2ede88d",
   "metadata": {},
   "source": [
    "#### 1.1.2 `get_metadata(cls, DATA_DIR)`\n",
    "This function standardizes the process of loading supplemental clinical or descriptive data associated with each class.\n",
    "\n",
    "* **Functionality:** It attempts to load an Excel file named `${cls}.metadata.xlsx` from the `DATA_DIR`.\n",
    "* **Output Structure:** If the file exists, it is loaded into a pandas DataFrame; otherwise, the function returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb40476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(cls, DATA_DIR= None):\n",
    "    '''\n",
    "    Loads the metadata Excel file associated with a specific diagnostic class.\n",
    "\n",
    "    The function constructs the expected file path for the metadata based on the class\n",
    "    name and attempts to read it into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        cls (str): The name of the class (e.g., 'COVID', 'Normal').\n",
    "        DATA_DIR (str, optional): The root directory of the dataset. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or None: The metadata DataFrame if the file exists, \n",
    "                                  otherwise returns None.\n",
    "    '''\n",
    "    # Construct the full path to the metadata Excel file using f-strings\n",
    "    metadata_path = os.path.join(DATA_DIR, f'{cls}.metadata.xlsx')\n",
    "    \n",
    "    # Check if the metadata file exists at the constructed path\n",
    "    if os.path.exists(metadata_path):\n",
    "        # Read the Excel file into a pandas DataFrame\n",
    "        df = pd.read_excel(metadata_path)\n",
    "        return df\n",
    "        \n",
    "    # If the file does not exist, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2261a-fbe6-45f8-bdd1-66a1267ff90a",
   "metadata": {},
   "source": [
    "### 1.2 Data Consolidation and Saving\n",
    "\n",
    "After all individual class data have been aggregated into `all_pairs` (list of image/mask tuples) and `all_meta` (list of metadata DataFrames), this part of the script finalizes the dataset preparation.\n",
    "\n",
    "#### 1.2.1 Data Summary\n",
    "The total counts of the aggregated records are printed to confirm that the data loading step was complete:\n",
    "* The script confirms the **Total image/Mask pairs** count using `len(all_pairs)`.\n",
    "* The script also confirms the **Total metadata records** count after concatenating all class-specific metadata.\n",
    "\n",
    "| Class | Image/Masks pairs loaded | Metadata pairs loaded |\n",
    "| :--- | :--- | :---\n",
    "| `COVID` | 3616 | 3616 |\n",
    "| `Normal` | 10192 | 10192 |\n",
    "| `Viral Pneumonia` | 1345 | 1345 |\n",
    "| `Lung_Opacity` | 6012 | 6012 |\n",
    "| `Healthy` | 10192 | 10192 |\n",
    "| `Unhealthy(all diseases lungs images)` | 10973 | 10973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee4defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID: 3616 image-mask pairs loaded Successfully !\n",
      "COVID: Metadata loaded. 3616 recored successfully !\n",
      "Normal: 10192 image-mask pairs loaded Successfully !\n",
      "Normal: Metadata loaded. 10192 recored successfully !\n",
      "Viral Pneumonia: 1345 image-mask pairs loaded Successfully !\n",
      "Viral Pneumonia: Metadata loaded. 1345 recored successfully !\n",
      "Lung_Opacity: 6012 image-mask pairs loaded Successfully !\n",
      "Lung_Opacity: Metadata loaded. 6012 recored successfully !\n"
     ]
    }
   ],
   "source": [
    "# Define the root directory for the dataset\n",
    "DATA_DIR = './data'\n",
    "# Define the four classes for which data is being loaded\n",
    "classes = ['COVID', 'Normal', 'Viral Pneumonia', 'Lung_Opacity']\n",
    "\n",
    "# Initialize lists to store all image/mask pairs and metadata DataFrames\n",
    "all_pairs, all_meta = [], []\n",
    "\n",
    "# Loop through each class name to load and aggregate data\n",
    "for cls in classes:\n",
    "    # 1. Load image and mask paths for the current class using the utility function\n",
    "    pairs = get_image_mask_pairs(cls, DATA_DIR= DATA_DIR)\n",
    "    # Extend the list with the paths found for the current class\n",
    "    all_pairs.extend(pairs)\n",
    "    # Print a confirmation message\n",
    "    print(f'{cls}: {len(pairs)} image-mask pairs loaded Successfully !')\n",
    "    \n",
    "    # 2. Load the metadata DataFrame for the current class\n",
    "    meta = get_metadata(cls, DATA_DIR= DATA_DIR)\n",
    "    \n",
    "    # Check if the metadata was successfully loaded\n",
    "    if meta is not None:\n",
    "        # Append the loaded DataFrame to the list of all metadata\n",
    "        all_meta.append(meta)\n",
    "        # Print a confirmation message\n",
    "        print(f'{cls}: Metadata loaded. {len(meta)} recored successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56147a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image/Mask pairs: 21165\n",
      "Total metadata records: 21165\n"
     ]
    }
   ],
   "source": [
    "# Print the total count of all image/mask pairs loaded\n",
    "print(f'Total image/Mask pairs: {len(all_pairs)}')\n",
    "\n",
    "# Check if the list of metadata DataFrames is not empty\n",
    "if all_meta:\n",
    "    # Concatenate all individual metadata DataFrames into a single master DataFrame\n",
    "    meta_df = pd.concat(all_meta, ignore_index= True)\n",
    "    # Print the total count of all consolidated metadata records\n",
    "    print(f'Total metadata records: {len(meta_df)}')\n",
    "else:\n",
    "    # If no metadata was loaded, set the master DataFrame to None\n",
    "    meta_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762085f-9158-4214-86f3-5cabfaaab8f3",
   "metadata": {},
   "source": [
    "#### 1.2.2 Final File Persistence\n",
    "The aggregated data is structured into two pandas DataFrames and saved as CSV files for efficient loading in downstream notebooks.\n",
    "* The image and mask paths are converted to `pairs_df` and saved as **`./data/all_image_mask_pairs.csv`**.\n",
    "* The concatenated metadata is saved as **`./data/all_metadata.csv`**.\n",
    "\n",
    "This step marks the completion of the physical data indexing and preparation stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad11b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_image_mask_pairs CSV file created successfully !\n",
      "all_metadata CSV file created successfully !\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame from the aggregated list of image/mask paths\n",
    "# Columns are explicitly named: 'image_path', 'mask_path', and 'class'\n",
    "pairs_df = pd.DataFrame(all_pairs, columns= ['image_path', 'mask_path', 'class'])\n",
    "\n",
    "# Save the DataFrame containing all image and mask indices to a CSV file\n",
    "# index=False prevents pandas from writing row numbers to the file\n",
    "pairs_df.to_csv('./data/all_image_mask_pairs.csv', index= False)\n",
    "\n",
    "# Print a confirmation message for the image/mask pairs file\n",
    "print(f'all_image_mask_pairs CSV file created successfully !')\n",
    "\n",
    "# Save the consolidated metadata DataFrame to a separate CSV file\n",
    "meta_df.to_csv('./data/all_metadata.csv', index= False)\n",
    "\n",
    "# Print a confirmation message for the metadata file\n",
    "print(f'all_metadata CSV file created successfully !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db18e990-3a31-4539-8d0a-3f4a5928408d",
   "metadata": {},
   "source": [
    "## Section 2: Classification Mapping Configuration\n",
    "\n",
    "This section is dedicated to establishing the **taxonomy** for the entire deep learning project. It defines the three hierarchical classification schemes (four-class, binary, and three-class unhealthy) and creates both the **class-to-index** and **index-to-class** mappings. These six dictionaries are then permanently saved as JSON files, ensuring consistent numerical encoding of class labels across all subsequent training and evaluation stages.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Configuration of Output File Paths\n",
    "\n",
    "The first step defines the explicit file paths where the six mapping configuration files will be stored in the `./data/` directory.\n",
    "\n",
    "| File Name | Purpose |\n",
    "| :--- | :--- |\n",
    "| `class_mapping_path` | Four-class mapping (Class $\\rightarrow$ Index) |\n",
    "| `healthy_binary_mapping_path` | Binary mapping (Class $\\rightarrow$ Index) |\n",
    "| `unhealthy_mapping_path` | Unhealthy-specific mapping (Class $\\rightarrow$ Index) |\n",
    "| `class_index_mapping_path` | Four-class reverse mapping (Index $\\rightarrow$ Class) |\n",
    "| `healthy_binary_index_mapping_path` | Binary reverse mapping (Index $\\rightarrow$ Class) |\n",
    "| `unhealthy_index_mapping_path` | Unhealthy-specific reverse mapping (Index $\\rightarrow$ Class) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e1566f9-2dda-436f-8dca-04279d1bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_path = './data/class_mapping.json'\n",
    "healthy_binary_mapping_path = './data/healthy_binary_mapping.json'\n",
    "unhealthy_mapping_path = './data/unhealthy_mapping.json'\n",
    "class_index_mapping_path = './data/index_mapping.json'\n",
    "healthy_binary_index_mapping_path = './data/healthy_binary_index_mapping.json'\n",
    "unhealthy_index_mapping_path = './data/unhealthy_index_mapping.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76c759-1bb5-4564-bc08-778e2a707ab0",
   "metadata": {},
   "source": [
    "### 2.2 Creating and Saving Class-to-Index Mappings\n",
    "\n",
    "Three primary dictionary mappings are defined to convert descriptive class names into numerical indices suitable for model training. Each is immediately saved to a JSON file.\n",
    "\n",
    "#### 2.2.1 Four-Class Mapping (`class_mapping.json`)\n",
    "This is the standard multi-class mapping used for general classification training.\n",
    "\n",
    "$$\\text{class\\_mapping} = \\{\\text{'COVID': 0, 'Normal': 1, 'Viral Pneumonia': 2, 'Lung\\_Opacity': 3}\\}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0c9f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Mapping json file created Successfully !\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {'COVID': 0, 'Normal': 1, 'Viral Pneumonia': 2, 'Lung_Opacity': 3}\n",
    "\n",
    "with open(class_mapping_path , 'w') as f:\n",
    "    json.dump(class_mapping, f, indent= 4)\n",
    "\n",
    "print('Class Mapping json file created Successfully !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37201e5-8bdd-4b39-9397-b7a965161d36",
   "metadata": {},
   "source": [
    "#### 2.2.2 Binary Mapping (`healthy_binary_mapping.json`)\n",
    "This mapping supports the **Stage 1: Binary Classification (Triage)** objective, distinguishing between healthy and diseased states.\n",
    "\n",
    "$$\\text{healthy\\_binary\\_mapping} = \\{\\text{'Healthy': 0, 'Unhealthy': 1}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec5edf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy binary mapping json file created successfully !\n"
     ]
    }
   ],
   "source": [
    "healthy_binary_mapping = {'Healthy': 0, 'Unhealthy': 1}\n",
    "with open(healthy_binary_mapping_path, 'w') as f:\n",
    "    json.dump(healthy_binary_mapping, f, indent= 2)\n",
    "\n",
    "print('Healthy binary mapping json file created successfully !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2801888-26b0-49e0-bf13-721d32991c6e",
   "metadata": {},
   "source": [
    "#### 2.2.3 Unhealthy Mapping (`unhealthy_mapping.json`)\n",
    "This mapping supports the **Stage 2: Specific Disease Classification** objective, focusing only on the three pathological classes.\n",
    "\n",
    "$$\\text{unhealthy\\_mapping} = \\{\\text{'COVID': 0, 'Viral Pneumonia': 1, 'Lung Opacity': 2}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab1f0661-3f8a-4c84-8ce7-8963d41fcd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unhealthy mapping json file created successfully !\n"
     ]
    }
   ],
   "source": [
    "unhealthy_mapping = {'COVID': 0, 'Viral Pneumonia': 1, 'Lung Opacity': 2}\n",
    "with open(unhealthy_mapping_path, 'w') as f:\n",
    "    json.dump(unhealthy_mapping, f, indent= 3)\n",
    "\n",
    "print('Unhealthy mapping json file created successfully !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da7e24-68a4-4d30-a3e6-eb7d6729e2da",
   "metadata": {},
   "source": [
    "### 2.3 Generating and Saving Index-to-Class Mappings\n",
    "\n",
    "The reverse mappings are generated using a simple dictionary comprehension on the primary mappings. These are essential for converting a model's numerical output (index) back into a human-readable class label during prediction and evaluation.\n",
    "\n",
    "* **`class_index_mapping`** is generated from `class_mapping`.\n",
    "* **`healthy_binary_index_mapping`** is generated from `healthy_binary_mapping`.\n",
    "* **`unhealthy_index_mapping`** is generated from `unhealthy_mapping`.\n",
    "\n",
    "All three reverse mappings are then saved to their respective JSON files, concluding the data configuration stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31477c54-be99-4613-ad9f-63365dc4574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index_mapping = {index: class_name for class_name, index in class_mapping.items()}\n",
    "healthy_binary_index_mapping = {index: healthy_class for healthy_class, index in healthy_binary_mapping.items()}\n",
    "unhealthy_index_mapping = {index: unhealthy_class for unhealthy_class, index in unhealthy_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f22a09a4-b0bf-4635-b24f-665e56141fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Index Mapping json file created Successfully !\n"
     ]
    }
   ],
   "source": [
    "with open(class_index_mapping_path , 'w') as f:\n",
    "    json.dump(class_index_mapping, f, indent= 4)\n",
    "\n",
    "print('Class Index Mapping json file created Successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd52e6d-5d73-4f83-9986-d12804cf42b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy Binary Index Mapping json file created Successfully !\n"
     ]
    }
   ],
   "source": [
    "with open(healthy_binary_index_mapping_path , 'w') as f:\n",
    "    json.dump(healthy_binary_index_mapping, f, indent= 4)\n",
    "\n",
    "print('Healthy Binary Index Mapping json file created Successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c73905-66a4-4eab-8052-2d02173c3f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unhealthy Index Mapping json file created Successfully !\n"
     ]
    }
   ],
   "source": [
    "with open(unhealthy_index_mapping_path , 'w') as f:\n",
    "    json.dump(unhealthy_index_mapping, f, indent= 4)\n",
    "\n",
    "print('Unhealthy Index Mapping json file created Successfully !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
